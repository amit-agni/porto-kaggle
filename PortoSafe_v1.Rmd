---
title: "Porto Safe "
output: html_notebook
---
Objective : is to predict the probability that a driver will initiate an auto insurance claim in the next year.
Data Description : Features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). 
Feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal.
Values of -1 indicate that the feature was missing from the observation. The target columns signifies whether or not a claim was filed for that policy holder.

First will setup the environment and load the data
```{r message=FALSE, warning=FALSE, echo=FALSE}
rm(list=ls())
gc()
library(caret)
setwd("/Mac Backup/OneDrive/R 2017/Projects/porto-kaggle")
setwd("C:/Amit/OneDrive/R 2017/Kaggle/Porto Safe Driver")

#Get data from CSV
train <- read.csv("./input/train.csv",header = TRUE)
test <- read.csv("./input/test.csv",header = TRUE)

```

Check whether train and test names are same and then combine them
```{r}
names(train)
names(test)
names(train[,-2]) == names(test)

#Combine train and test
dataset <- rbind(train[,-2],test)

```

Generate summary stats using describe

```{r}
str(dataset)
summary(dataset)
library(psych)
describe(dataset,IQR=TRUE, quant = c(0.25,0.75))
write.csv(describe(dataset,IQR=TRUE, quant = c(0.25,0.75)),"./output/describe.csv")

```

Separate continuous and categorical variables. Plot box plots and histograms of the continuous variables
```{r}
variables <- colnames(dataset)
continuous_variables <- variables[!grepl("bin",variables) & !grepl("cat",variables)][2:27]

#boxplot.matrix(as.matrix(head(dataset[,continuous_variables])))
library(tidyverse)

ggplot(gather(dataset[,continuous_variables])) +
    geom_histogram(aes(x=value)) +
    facet_wrap(~key,scales = "free") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1,size=7),
          axis.text.y = element_text(angle = 45, hjust = 1,size=7),
          strip.text.x = element_text(size=7),
          strip.text.y = element_text(size=7))
ggsave("./output/histogram 01Nov17.jpg")

ggplot(gather(dataset[,continuous_variables])) +
    geom_boxplot(aes(x=key,y=value)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1,size=7),
          axis.text.y = element_text(angle = 45, hjust = 1,size=7),
          strip.text.x = element_text(size=7),
          strip.text.y = element_text(size=7))
ggsave("./output/boxplot 01Nov17.jpg")

```

Extract categorial and variables with binary values and plot histograms

```{r}

categorical_variables <- variables[grepl("bin",variables) | grepl("cat",variables)]
head(dataset[,categorical_variables])


table(head(dataset[,categorical_variables]))


```



The non observed values are supposed to have -1. Lets check them, how many of them are there (in the whole train set)

```{r}


#Use a smaller dataset for trialing the end to end regression
#Imputation with knn using the original set taking very long time
#Split around 10000 rows

dim(train)
split<-createDataPartition(train$id, p = 0.01, list = FALSE)
dataset<-train[split,]
dim(dataset)

#val<-mtcars[-split,]




dim(train)
#Actual missing
sapply(train, function(x) sum(x == -1) )
#Percentage
sapply(train, function(x) format(100* (sum(x == -1) / 595212), digits = 3))

```

There are quite a few null observations in 
ps_ind_05_cat 1%
ps_reg_03 18%
ps_car_03_cat 69%
ps_car_05_cat 45%
ps_car_07_cat 2%
ps_car_14 7%

These will have to be imputed. Rest are small percentages and can be ignored at this stage.
Source : https://www.analyticsvidhya.com/blog/2016/12/practical-guide-to-implement-machine-learning-with-caret-package-in-r-with-practice-problem/
Lets impute the sample dataset using kNN

```{r}

#Convert the non-observed values to NA (as required by kNN preProcess)
dataset[dataset == -1] <- NA
#Recheck the percentages
sapply(dataset, function(x) sum(is.na(x)))

#Remove Id
dataset$id <- NULL
names(dataset)




#Imputing missing values using KNN.

#Imputing also scales the data, so remove target from imputation
temp <- dataset[,-1]

preProcValues <- preProcess(temp, method = c("knnImpute"))
#install.packages("RANN")
library(RANN)
sum(is.na(dataset))
temp <- predict(preProcValues, temp)
sum(is.na(dataset))
#[1] 0

#add the target column back, retain the column name

names(dataset)
dataset <- cbind(dataset[,1,drop = FALSE],temp)
colnames(dataset[,"dataset[,1]"]) <- "target"



```

Set the parameters for caret

```{r}
names(dataset)
str(dataset)

control <- trainControl(method="repeatedcv", number=5, repeats=1)
seed <- 7

class(seed)

metric <- "Accuracy"

#Some models needs Scaling
preProcess=c("center", "scale")

```

Now try the logistic regression 

```{r}
# Logistic Regression
#glm is expecting target to be factor to do classification
#Still giving : prediction from a rank-deficient fit may be misleading
dataset$target <- as.factor(dataset$target)

set.seed(seed)
fit.glm <- train(target~., data=dataset, method="glm", metric=metric, trControl=control)
```

use only 2 variables
```{r}

names(dataset)
str(dataset)
fit.glm <- train(target~ps_ind_01+ps_ind_03, data=dataset, method="glm", metric=metric, trControl=control)

```








